# 動作空間設計文檔

## 概述

本文檔說明 Agent 的動作空間設計。分為兩部分：
1. **當前實作**：目前已經實現的動作空間
2. **未來規劃**：多技能系統完成後的目標動作空間

---

# 當前實作（Current Implementation）

## 動作空間總覽

### 離散動作（7 個選項）

| ID | 動作 | 說明 |
|----|------|------|
| 0 | MOVE_FORWARD | 向前移動 |
| 1 | MOVE_BACKWARD | 向後移動 |
| 2 | TURN_LEFT | 左轉 |
| 3 | TURN_RIGHT | 右轉 |
| 4 | OUTER_SLASH | 外圈刮 |
| 5 | MISSILE | 飛彈 |
| 6 | HAMMER | 鐵錘 |

### 連續 Actor（1 個）

| ID | Actor 名稱 | 輸出範圍 | 說明 |
|----|-----------|---------|------|
| 0 | aim_offset | 連續值 | 施法時的瞄準偏移（僅 action=3 時使用）|

### 特徵維度

當前使用 **27 維**特徵向量，詳見 `長期規劃-特徵工程.md`。

---

## 程式碼架構

### Agent 類別（ai/agent.py）

```python
class HybridPPOAgent:
    """
    混合動作空間 PPO Agent
    使用 squared probability distribution 而非 softmax
    """

    def __init__(
        self,
        n_features: int,           # 27
        n_discrete_actions: int,   # 4
        gamma: float = 0.99,
        lmbda: float = 0.95,
        epsilon: float = 0.2,
        sigma_init: float = 0.6,
        sigma_min: float = 0.15,
        sigma_decay: float = 0.9998
    ):
        # 離散 Actor 權重: (7, n_features)
        self.w_actor_discrete = np.random.randn(n_discrete_actions, n_features) * 0.01

        # 連續 Actor 權重: (n_features,)
        self.w_actor_continuous_mu = np.random.randn(n_features) * 0.01

        # Critic 權重: (n_features,)
        self.w_critic = np.random.randn(n_features) * 0.01

    def get_action(self, observation: np.ndarray) -> Tuple:
        """
        選擇動作

        Returns:
            (action_discrete, action_continuous, prob_discrete, mu, value, logits)
        """
        # 離散動作：squared probability
        logits = self.w_actor_discrete @ observation
        probs = squared_prob(logits)
        action_discrete = np.random.choice(7, p=probs)

        # 連續動作：高斯分佈
        mu = self.w_actor_continuous_mu @ observation
        action_continuous = np.random.normal(mu, self.sigma)

        # 價值估計
        value = self.w_critic @ observation

        return action_discrete, action_continuous, probs[action_discrete], mu, value, logits
```

### 動作執行流程（Player.execute_action）

```python
# game/player.py

class Player:
    def execute_action(
        self,
        action_discrete: int,
        action_continuous: float,
        physics: PhysicsSystem,
        skill_executor: SkillExecutor
    ) -> str:
        """
        執行 Agent 動作

        Args:
            action_discrete: 0=前進, 1=後退, 2=左轉, 3=右轉, 4-6=施法
            action_continuous: 瞄準偏移（僅 action=3 時使用）

        Returns:
            事件描述字串
        """
        if action_discrete == 0:  # MOVE_FORWARD
            success = physics.move_forward(self.entity, speed=self.config.move_speed)
            return "HIT WALL!" if not success else ""

        elif action_discrete == 1:  # MOVE_BACKWARD
            success = physics.move_backward(self.entity, speed=self.config.move_speed)
            return "HIT WALL!" if not success else ""

        elif action_discrete == 2:  # TURN_LEFT
            physics.rotate_entity(self.entity, self.config.turn_speed)
            return ""

        elif action_discrete == 3:  # TURN_RIGHT
            physics.rotate_entity(self.entity, -self.config.turn_speed)
            return ""

        elif action_discrete == 4:  # OUTER_SLASH
            ...
        elif action_discrete == 5:  # MISSILE
            ...
        elif action_discrete == 6:  # HAMMER
            ...

        return ""
```

### PlayerConfig（玩家配置）

```python
# game/player.py

@dataclass
class SkillConfig:
    skill_id: str
    name: str = ""
    cooldown_ticks: int = 30
    wind_up_ticks: int = 4
    can_move_during_wind_up: bool = True
    requires_aim: bool = False
    aim_actor_count: int = 0
    damage: float = 100.0
    range: float = 6.0
    angle_tolerance: float = 0.4
    extra_params: Dict[str, float] = field(default_factory=dict)

@dataclass
class PlayerConfig:
    move_speed: float = 0.6
    turn_speed: float = 0.4
    max_health: float = 100.0
    skills: Dict[str, SkillConfig] = field(default_factory=dict)
```

### 權重導出格式

```python
def get_weights(self) -> dict:
    return {
        'w_actor_discrete': self.w_actor_discrete.tolist(),      # (7, 27)
        'w_aim_actors': [w.tolist() for w in self.w_aim_actors], # 2 × (27,)
        'w_critic': self.w_critic.tolist(),                      # (27,)
        'sigma': self.sigma
    }
```

---

# 未來規劃（Planned Future State）

## 動作空間目標

### 離散動作（11 個選項）

| ID | 動作 | 說明 |
|----|------|------|
| 0 | MOVE_FORWARD | 向前移動 |
| 1 | TURN_LEFT | 左轉 |
| 2 | TURN_RIGHT | 右轉 |
| 3 | SKILL_OUTER_SLASH | 外圈刮 |
| 4 | SKILL_MISSILE | 飛彈 |
| 5 | SKILL_HAMMER | 鐵錘 |
| 6 | SKILL_DASH | 閃現 |
| 7 | SKILL_SOUL_CLAW | 靈魂爪 |
| 8 | SKILL_SOUL_PALM | 靈魂掌 |
| 9 | SKILL_BLOOD_POOL | 血池 |
| 10 | SKILL_SUMMON_PACK | 召喚血包 |

### 連續 Actor（6 個）

| ID | Actor 名稱 | 對應技能 | 輸出範圍 | 說明 |
|----|-----------|---------|---------|------|
| 0 | aim_missile | 飛彈 | [-π, π] | 發射角度偏移 |
| 1 | aim_hammer | 鐵錘 | [-π, π] | 錘擊角度偏移 |
| 2 | aim_dash_direction | 閃現 | [-π, π] | 閃現方向 |
| 3 | aim_dash_facing | 閃現 | [-π, π] | 閃現後朝向 |
| 4 | aim_claw | 靈魂爪 | [-π, π] | 爪擊角度偏移 |
| 5 | aim_palm | 靈魂掌 | [-π, π] | 掌擊角度偏移 |

### 技能與 Actor 的映射

```python
SKILL_TO_ACTORS = {
    3: [],           # 外圈刮 - 無需瞄準
    4: [0],          # 飛彈 - aim_missile
    5: [1],          # 鐵錘 - aim_hammer
    6: [2, 3],       # 閃現 - aim_dash_direction, aim_dash_facing
    7: [4],          # 靈魂爪 - aim_claw
    8: [5],          # 靈魂掌 - aim_palm
    9: [],           # 血池 - 無需瞄準
    10: [],          # 召喚血包 - 無需瞄準
}
```

---

## 規劃中的程式碼架構

### Agent 類別修改

```python
class HybridPPOAgent:
    # 動作空間定義
    N_DISCRETE_ACTIONS = 11
    N_AIM_ACTORS = 6

    def __init__(self, n_features: int, ...):
        # 離散 Actor: (11, n_features)
        self.w_actor_discrete = np.random.randn(
            self.N_DISCRETE_ACTIONS, n_features
        ) * 0.01

        # 連續 Actors: 每個 Actor 有自己的權重 (n_features,)
        self.w_aim_actors = [
            np.random.randn(n_features) * 0.01
            for _ in range(self.N_AIM_ACTORS)
        ]

        # Critic: (n_features,)
        self.w_critic = np.random.randn(n_features) * 0.01

    def select_action(
        self,
        features: np.ndarray,
        skill_available: np.ndarray = None
    ) -> Tuple[int, List[float]]:
        """
        選擇動作

        Args:
            features: 特徵向量 (n_features,)
            skill_available: 技能可用性遮罩 (8,)，True 表示可用

        Returns:
            (discrete_action, aim_values)
            - discrete_action: 0-10 的離散動作
            - aim_values: 對應技能的瞄準值列表
        """
        probs = self._compute_discrete_probs(features, skill_available)
        discrete_action = np.random.choice(self.N_DISCRETE_ACTIONS, p=probs)

        aim_values = []
        if discrete_action >= 3:  # 是技能
            actor_indices = self.SKILL_TO_ACTORS.get(discrete_action, [])
            for actor_idx in actor_indices:
                aim_value = self._compute_aim_value(features, actor_idx)
                aim_values.append(aim_value)

        return discrete_action, aim_values
```

### 技能可用性遮罩

```python
def get_skill_availability(world: GameWorld) -> np.ndarray:
    """
    獲取技能可用性遮罩

    Returns:
        (8,) 的布林陣列，True 表示技能可用
    """
    availability = np.zeros(8, dtype=bool)
    cd_manager = world.skill_executor.cooldown_manager

    for skill_id in range(1, 9):
        availability[skill_id - 1] = cd_manager.is_ready(skill_id)

    return availability
```

---

## 規劃中的權重導出格式

```python
def export_weights(self) -> dict:
    return {
        "w_actor_discrete": self.w_actor_discrete.tolist(),  # (11, n_features)
        "w_aim_actors": [w.tolist() for w in self.w_aim_actors],  # 6 × (n_features,)
        "w_critic": self.w_critic.tolist(),  # (n_features,)
        "sigma": self.sigma
    }
```

---

## 施法期間的動作限制

某些技能施放期間可能限制移動（由 `SkillConfig.can_move_during_wind_up` 控制）：

```python
def select_action(self, features, skill_available, is_casting, can_move_while_casting):
    if is_casting:
        if can_move_while_casting:
            # 只能選擇移動動作，遮罩所有技能
            skill_available = np.zeros(8, dtype=bool)
        else:
            # 完全不能動作
            return -1, []

    return self._select_action_internal(features, skill_available)
```

---

## 測試方法（規劃）

```python
def test_action_selection():
    agent = HybridPPOAgent(n_features=97)

    features = np.random.randn(97)
    features[-1] = 1.0  # Bias

    skill_available = np.ones(8, dtype=bool)

    discrete, aim_values = agent.select_action(features, skill_available)

    assert 0 <= discrete <= 10

    if discrete == 6:  # 閃現
        assert len(aim_values) == 2
    elif discrete in [4, 5, 7, 8]:  # 需要瞄準的技能
        assert len(aim_values) == 1
    else:
        assert len(aim_values) == 0

def test_skill_masking():
    agent = HybridPPOAgent(n_features=97)
    features = np.random.randn(97)

    # 只有前 3 個技能可用
    skill_available = np.array([True, True, True, False, False, False, False, False])

    for _ in range(100):
        discrete, _ = agent.select_action(features, skill_available)
        if discrete >= 3:
            assert discrete <= 5
```

---

## 實作路線圖

| 階段 | 內容 | 狀態 |
|------|------|------|
| 1 | 7 離散動作 + 2 連續 Actor | ✅ 已完成 |
| 2 | Player 類別重構（SkillConfig） | ✅ 已完成 |
| 3 | 多技能系統（8 技能 + CD） | ⏳ 待實作 |
| 4 | 11 離散動作 + 6 連續 Actor | ⏳ 待實作 |
| 5 | 技能可用性遮罩 | ⏳ 待實作 |
